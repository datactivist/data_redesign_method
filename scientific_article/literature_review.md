Task: What are the available mechanism to ensure dataset can adapt to the data-literacy level of the user ?

We summarize mechanisms that allow datasets and their interfaces to adapt to users’ data-literacy levels, organized across documentation/metadata, visualization and interface adaptivity, interaction support, assessment and user modeling, and governance/access.

Documentation and metadata
- Structured, user-centered dataset documentation: Data Cards present essential facts (sources, collection, intended use, risks) in concise, audience-aware summaries that can be tuned for different stakeholders to improve understanding and trust ([1.1]). 
- Machine-readable datasheets and standardized metadata: Open, machine-readable datasheets and Croissant-RAI improve discoverability and interoperability, enabling automated surfacing of the right details for different user groups and workflows (e.g., beginners see high-level summaries; experts access detailed schema and provenance) ([1.1]). 
- In-situ explanatory metadata: Explicit labels, legends, KPI definitions, and clear statements of data sources/limitations embedded in dashboards reduce misinterpretation and support low-literacy users ([1.2], [1.3]).

Visualization and interface adaptivity
- Tailoring modes: Enable customization (user-driven changes), personalization (role-based defaults at load), and automatic adaptive behavior (real-time adjustments from user models) to match literacy and tasks ([1.1]).
- Progressive disclosure and simplification: Start with minimal defaults (e.g., few charts) and consistent encodings; provide drill-downs and automatic highlighting to manage cognitive load for novices while leaving expert affordances available ([1.2], [1.3]).
- Visualization recommenders: Use perceptual guidelines and preference- or content-based recommenders (e.g., VizRec) to suggest appropriate chart types and reduce choice overload, supporting non-experts ([2.1]).
- User/context-adaptive taxonomy: Adapt to user traits (e.g., statistical expertise, graphical literacy) and states/intent (monitoring vs analysis), as different tasks require different visual complexity and interaction ([3.1], [3.2]).
- Real-time guidance: Dynamically emphasize relevant elements or de-emphasize clutter based on inferred task and cognitive capacity to aid users with lower perceptual speed or working memory ([4.1]).

Interaction support
- Embedded guidance: Provide tutorials, pop-ups, videos, annotations, explicit interpretation of visuals, and highlight interactive regions; show onboarding to first-time or inactive users ([1.2]).
- Task-first interactivity: Support drill-down, zoom, and sort with sensible defaults; allow saving/sharing of filtered views to scaffold collaborative sensemaking across literacy levels ([1.2], [1.3]).
- Workflow and community learning: Capture workflows and surface community-authored tutorials to reduce frustration and support novice-to-expert transitions ([5.1]).

Assessment and user modeling
- Adaptive literacy assessment: Use computerized adaptive tests (CAT/IRT) for visualization literacy to quickly profile skills and drive interface defaults and help content ([1.4]).
- Behavioral telemetry and psychometrics: Infer tasks, expertise, and cognitive abilities from gaze and interaction logs to adapt assistance, highlight relevant data, and manage cognitive load ([4.1]).
- Human-centered user models: Build multi-dimensional models including domain expertise, cognitive factors, and task context; refine with reflective analytics and learning-curve modeling to improve recommendations over time ([6.1], [6.2], [6.3]).
- Preference capture for recommenders: Combine quality ratings, content tags, and collaborative filtering to personalize visualization choices ([2.1]).

Governance and access
- Transparency via provenance and paradata: Document data lineage, processing steps, and decision rationales to help users at different literacy levels evaluate trust and appropriateness ([1.3]).
- Ethical and contextual documentation: Augmented datasheets that capture domain-specific risks and representativeness support safe use and clearer expectations for non-expert stakeholders ([1.3]).
- Role-based workflows and permissions: Connect data sources and KPIs to user roles to prevent overload and expose the right granularity by default, with escalation paths for experts ([1.3]).

Design and effectiveness notes
- Empirical interviews with dashboard developers emphasize that mismatches in visual literacy are common; tailoring via customization/personalization/automatic adaptation is feasible and desirable ([1.1]). Implemented practices include minimal default charts, consistent colors, role-tailored filters, explicit interpretation, and training/onboarding ([1.2]).
- Adaptive visualization taxonomies should consider user traits (e.g., statistical expertise) and states (monitoring vs analysis). Paper-based validation shows utility for monitoring tasks, with a need for richer interactive features for analysis ([3.1], [3.2]).
- Adaptive assessment using CAT/IRT halves test length while maintaining reliability, making ongoing literacy profiling practical in production systems ([1.4]).
- Recommender-based visualization selection reduces choice overload and can align with user preferences by combining perceptual guidelines and personalized signals ([2.1]).
- Real-time user modeling from gaze/behavior can identify users with lower perceptual speed or working memory and trigger adaptive highlighting or simplification ([4.1]).

Practical implementation checklist
- Provide layered documentation: high-level summaries, in-situ definitions, and links to machine-readable datasheets ([1.2], [1.3]).
- Default to progressive disclosure: minimal, consistent visuals with clear drill-down; enable role-based presets and automatic highlights ([1.2], [1.1]).
- Add a visualization recommender and guidance: suggest chart types and offer contextual explanations; capture preferences ([2.1]).
- Embed adaptive onboarding and help: tutorials for first-time/inactive users; highlight interactivity; capture and share workflows ([1.2], [5.1]).
- Incorporate literacy profiling and telemetry: brief CAT/IRT tests; passive gaze/interaction modeling to adapt interface complexity ([1.4], [4.1]).
- Ensure transparency and access control: provenance, ethical datasheets, and role-based permissions to match information depth to user need ([1.3]).

References:
[1.1] Data Quality, Mismatched Expectations, and Moving Requirements: The Challenges of User-Centred Dashboard Design. Mohammed Alhamadi, Omar Alghamdi, Sarah Clinch, Markel Vigo. Nordic Human-Computer Interaction Conference (2022). https://doi.org/10.1145/3546155.3546708
    Context: "Interactive dashboards present users with challenges in understanding and verifying information, often due to information overload, visual literacy gaps, and developers prioritizing visual appeal over functional effectiveness. Developers need a thorough understanding of user perspectives and problems, as users' literacy often doesn't align with dashboard requirements. Tailoring mechanisms such as customization (user-initiated changes), personalization (system-driven at creation/loading), and automatic adaptations (real-time updates based on user models) are considered desirable and feasible solutions to cater to individual user needs and characteristics. Empirical findings indicate developers are largely aware of user problems and identified a new one: users' tendency to verify displayed data. Poor visual literacy and pressure to deviate from design guidelines are identified as causes for issues. Design recommendations include focusing on data presentation and visual literacy, and considering user involvement in development to improve usability, as evidenced by tools like 'We Rate Covid Dashboards' showing most dashboards are poorly rated."
[1.2] Data Quality, Mismatched Expectations, and Moving Requirements: The Challenges of User-Centred Dashboard Design. Mohammed Alhamadi, Omar Alghamdi, Sarah Clinch, Markel Vigo. Nordic Human-Computer Interaction Conference (2022). https://doi.org/10.1145/3546155.3546708
    Context: "For **Documentation/metadata**, implemented adaptations include adding extra helping information like axes labels, data points for context, legends, and definitions of KPIs. Emphasizing dashboard capabilities and limitations is also an implemented approach to reduce confusion.  Regarding **Visualization/interface adaptivity**, implemented mechanisms involve using consistent colors for the same data across dashboards, creating visualizations based on KPIs, and utilizing rules to automatically highlight changes. Design recommendations include using a maximum of two charts by default. Interface adaptivity is addressed by implemented responsive layouts and suggested changes to filters based on user roles and presenting information based on user motivation.  **Interaction support** is provided through implemented instructions via pop-up messages, annotations, videos, and tutorials. Other support mechanisms include displaying videos for functionality use, highlighting clickable areas, and enabling a mechanism to share filtered dashboards. A suggested interaction feature is enabling sorting of dashboard content. Explicitly interpreting visualizations is also an implemented support.  For **Assessment/user modeling**, implemented adaptations involve showing suggestions to improve user performance, educating users about inappropriate visualization requests, and adapting training by showing tutorials to first-time users or those who haven't logged in recently. Collecting feedback to enhance training is also implemented. Presenting information based on what motivates the user is a suggested personalization approach."
[1.3] Data Quality, Mismatched Expectations, and Moving Requirements: The Challenges of User-Centred Dashboard Design. Mohammed Alhamadi, Omar Alghamdi, Sarah Clinch, Markel Vigo. Nordic Human-Computer Interaction Conference (2022). https://doi.org/10.1145/3546155.3546708
    Context: "The excerpt identifies various user challenges in dashboard design and proposes adaptations, categorized by implementation status (Implemented/Suggested) and tailoring type (Customisation, Personalisation, Automatic Adaptation). For documentation/metadata, an adaptation suggested for 'Lack of Trust' is to show data source and metadata. For visualization/interface adaptivity, recommendations include combining data into smaller subsets with drill-down functionality, enabling users to keep relevant charts, and allowing changes in visualization type on demand. Design recommendations also involve using visualization guidelines, creating visuals based on questions and KPIs, and maintaining consistent color schemes. Interaction support is addressed by enabling drill-down and zoom into datasets. User modeling is implicitly supported by conducting workshops to understand user tools and educating users about information overload risks. For governance/access, the excerpt suggests using workflows that connect data sources to user roles to protect data access."
[1.4] Data Quality, Mismatched Expectations, and Moving Requirements: The Challenges of User-Centred Dashboard Design. Mohammed Alhamadi, Omar Alghamdi, Sarah Clinch, Markel Vigo. Nordic Human-Computer Interaction Conference (2022). https://doi.org/10.1145/3546155.3546708
    Context: "A significant challenge in dashboard design is the discrepancy between users' visual literacy and the requirements for effective dashboard use. To address this, developers should consider tailoring dashboards to individual user needs, which is deemed both desirable and feasible. The excerpt identifies three key mechanisms for adapting interfaces: 'customisation,' where users actively modify dashboard aspects; 'personalisation,' where the system adjusts the dashboard at creation or loading time; and 'automatic adaptations,' which involve real-time updates based on user models. These adaptive approaches aim to mitigate challenges stemming from visual literacy gaps and ineffective data presentation. Furthermore, the paper suggests that developers should account for varying visual literacy levels among users and the constraints of layouts when presenting information to foster engagement and trust. Efforts by public health officials to create tools and tutorials for users to become 'dashboard co-creators' and critically assess visualizations also represent a form of interaction support to improve data literacy."
[2.1] VizRec. Belgin Mutlu, Eduardo Veas, Christoph Trattner. ACM Transactions on Interactive Intelligent Systems (TiiS) (2016). https://doi.org/10.1145/2983923
    Context: "VizRec is a visualization recommender system designed to suggest personalized visualizations by considering user preferences and data aspects. For visualization/interface adaptivity, VizRec uses perceptual guidelines to reduce the number of recommendations, aiming to suggest visualizations that align with a user's analysis workflow. In terms of documentation/metadata, it employs tag vectors to describe visualization content for content-based filtering and combines this with quality ratings in a hybrid approach. For assessment/user modeling, the system uses a multi-dimensional scale to estimate quality aspects for collaborative filtering, and investigates how user interests and choices can be captured. An extensive crowd-sourced evaluation via Amazon Mechanical Turk was conducted to understand variability in preferred visualizations and assess quality. Design principles behind VizRec emphasize reducing combinatorial explosion through perceptual guidelines and incorporating personalization aspects."
[3.1] Toward a Taxonomy for Adaptive Data Visualization in Analytics Applications. Tristan Poetzsch, Panagiotis Germanakos, Lynn Huestegge. Frontiers in Artificial Intelligence (2020). https://doi.org/10.3389/frai.2020.00009
    Context: "This excerpt details an experiment evaluating a taxonomy for adaptive data visualization. For visualization/interface adaptivity, the study found an average suitability rating of 3.09 out of 5 for the taxonomy's proposed visualizations. An empirical finding indicated that monitoring tasks with higher data complexity were rated better, while the opposite was true for analysis tasks, suggesting different adaptivity needs based on task and complexity. The scalability in monitoring mode was considered useful, but analytic mode display options required more work. Regarding interaction support, a key design recommendation emerged: users missed interactive features like filtering and aggregating, noting that complex analysis typically requires such interaction, which was not available in the paper-based study. For assessment/user modeling, the research suggests that data visualizations should adapt to both user and context. Statistical expertise was identified as a relevant user trait for adaptation, and user intentions, specifically monitoring and analysis, should be differentiated as user states. The study itself did not fully consider user traits due to its paper-based nature."
[3.2] Toward a Taxonomy for Adaptive Data Visualization in Analytics Applications. Tristan Poetzsch, Panagiotis Germanakos, Lynn Huestegge. Frontiers in Artificial Intelligence (2020). https://doi.org/10.3389/frai.2020.00009
    Context: "The paper advocates for adaptive data visualizations tailored to both the user and the context. It proposes a user model that integrates user traits, states, strategies, and actions, identifying statistical expertise as a crucial user trait for adaptation. While the study's quantitative results for the taxonomy's visualization suitability were ambivalent (average rating 3.09 out of 5), the concept of an adaptive data visualization taxonomy was broadly endorsed by experts. A limitation of the study was its paper-based nature, which prevented full evaluation of a user-adaptive approach and the inclusion of interactive features like filtering, brushing, aggregating, and drilldown, which are deemed essential for processing complex data in analysis settings."
[4.1] User-adaptive information visualization: using eye gaze data to infer visualization tasks and user cognitive abilities. Ben Steichen, Giuseppe Carenini, Cristina Conati. Proceedings of the 2013 international conference on Intelligent user interfaces (2013). https://doi.org/10.1145/2449396.2449439
    Context: "This research focuses on user-adaptive information visualization, proposing the design of novel systems that can adapt to individual users in real-time. For **Assessment/user modeling**, the paper investigates using eye gaze data to predict a user's current visualization tasks and cognitive abilities like perceptual speed, visual working memory, and verbal working memory. These predictions were found to be significantly better than a baseline classifier. It also references prior work that utilized mouse click behavior and visualization selections to infer user expertise, preferences, and suboptimal usage patterns such as scanning, flipping, swapping, and drilling. For **Visualization/interface adaptivity**, interventions can involve recommending suitable visualizations or, as envisioned in this work, dynamically helping the user with the current visualization, for example, by highlighting relevant elements or adaptively deemphasizing non-relevant data to reduce cognitive load. An empirical finding noted is that low perceptual speed negatively impacts performance, suggesting that users with this characteristic could particularly benefit from adaptive interventions."
[5.1] Supporting Novice to Expert Transitions in User Interfaces. Andy Cockburn, Carl Gutwin, Joey Scarr, Sylvain Malacria. ACM Computing Surveys (CSUR) (2014). https://doi.org/10.1145/2659796
    Context: "For **Documentation/metadata**, the 'FollowUs' system integrates online tutorials within applications, captures user workflow, and enables community contributions for improvements, leading to higher task completion and lower frustration. The 'ShowMeHow' system assists knowledge transfer between software versions by translating commands and allowing users to repurpose tutorials.  **Visualization/interface adaptivity** includes the 'Chronicle' system, which visualizes workflows via a zoomable timeline. While user interface customization and adaptive systems offer user-driven or automatic reconfigurations, challenges exist as customization is deterred by 'satisficing' and 'paradox of the active user', and automatic adaptations can cause temporary performance dips.  **Interaction support** highlights the use of expanding rehearsal intervals for learning motor skills. It emphasizes the need to support 'strategic knowledge' (e.g., 'Detail, Aggregate, Manipulate' over 'Sequence by Operation'), with examples like formatting styles. Design recommendations for feedback include avoiding untimely interruptions like Clippy, while leveraging appropriate 'locus of control' mechanisms (push vs. pull, such as type-ahead features).  **Assessment/user modeling** involves systems like FollowUs and Chronicle that capture and analyze user workflows to aid in reflecting on interaction strategies.  **Governance/access** is supported through community input into tutorial content, as demonstrated by FollowUs's success in increasing task completion and reducing frustration with community-sourced materials."
[6.1] Adaptive Visualizations for Enhanced Data Understanding and Interpretation. Christos Amyrotos. Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization (2021). https://doi.org/10.1145/3450613.3459657
    Context: "Mechanisms for adapting visualization interfaces to a user's data-literacy level include adaptive visualization interfaces and various forms of user modeling. An "Adaptive Visualization Interface That Manages User’s Cognitive Load Based on Interaction Characteristics" has been proposed, directly addressing visualization/interface adaptivity by adjusting the interface based on observed user behavior to manage cognitive load. This is crucial for catering to different levels of data literacy.  Furthermore, user modeling plays a significant role in adaptation. Research highlights the "Impact of Individual Differences on User Experience with a Real-World Visualization Interface," indicating that understanding these variations is essential for personalized adaptation. Specific techniques involve the "Prediction of users’ learning curves for adaptation while using an information" interface. Additionally, user characteristics such as "locus of control influences compatibility with visualization style," suggesting that psychological traits can inform how visualizations are designed or adapted to individual users to enhance understanding and interpretation."
[6.2] Adaptive Visualizations for Enhanced Data Understanding and Interpretation. Christos Amyrotos. Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization (2021). https://doi.org/10.1145/3450613.3459657
    Context: "Existing data visualization tools often adopt a "one-size-fits-all approach," neglecting users' unique characteristics, needs, and individual differences, which can hinder data comprehension and effective decision-making, particularly for non-specialized users. To address this, a "human-centred adaptive data visualizations framework" is proposed. This framework incorporates a "multi-dimensional human-centred user model" that considers factors beyond traditional characteristics, including "cognitive factors, domain expertise and experience" and factors related to the business context like data, visualizations, and tasks. A "data visualization engine" then utilizes this user model to recommend "best-fit data visualizations." Furthermore, an "intelligent data analytics component" continuously refines the user model by "leveraging user interactions during the explorations" to assess and inform the user's expertise and experience. The goal is to develop "adaptive visualizations that will facilitate better data understanding, more efficient... and effective... data exploration," despite such adaptive interactions being "rarely applied to visual analytics in business.""
[6.3] Adaptive Visualizations for Enhanced Data Understanding and Interpretation. Christos Amyrotos. Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization (2021). https://doi.org/10.1145/3450613.3459657
    Context: "Mechanisms for adaptation include assessing user preferences for specific visualization types based on analytical tasks, such as preferring bar charts for comparison or line charts for trends, and developing more automated and user-friendly tools that reduce analysis steps and simplify data integration. A key approach involves formulating a "multi-dimensional human-centred user model" and a "rule-based engine" to adapt data visualization content. Future plans include using "reflective analytics, tracking and machine learning methodologies" to quantify user "expertise and experience" for informing this user model, potentially simplifying user registration by excluding less impactful human factors. Ultimately, a "generic data visualization engine" is envisioned to render appropriate visualizations for individual users based on specifications like data, user-model, and task."