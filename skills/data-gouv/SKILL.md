---
name: data-gouv
description: Skill professionnel pour Claude Code permettant d'acc√©der, t√©l√©charger et analyser les donn√©es ouvertes fran√ßaises via data.gouv.fr. Inclut une librairie Python compl√®te, des exemples de code, et une documentation d√©taill√©e des datasets les plus utilis√©s.
version: 2.1.0
author: Benoit Vinceneux
license: Licence Ouverte 2.0
tags: [opendata, france, data, api, python, datasets, statistics]
---

# Skill data.gouv.fr pour Claude Code

## ‚ö†Ô∏è Nature de ce skill

Ce skill est une **documentation + librairie Python**, **PAS un plugin avec des commandes interactives**.

**Ce que vous trouverez ici :**
- üìö Documentation de l'API data.gouv.fr
- üêç Librairie Python r√©utilisable
- üìä Datasets document√©s avec exemples
- üí° Code pr√™t √† l'emploi

**Ce que vous ne trouverez PAS ici :**
- ‚ùå Commandes slash (`/data-gouv-search`, etc.)
- ‚ùå Agents interactifs
- ‚ùå Requ√™tes en langage naturel

**Pour des commandes interactives**, utilisez le [MCP officiel data.gouv.fr](https://github.com/datagouv/datagouv-mcp).

---

## Vue d'ensemble

Ce skill fournit un acc√®s programmatique complet aux donn√©es ouvertes fran√ßaises h√©berg√©es sur [data.gouv.fr](https://www.data.gouv.fr/), le portail national des donn√©es publiques.

**Capacit√©s principales :**
- üîç Recherche de datasets via l'API officielle
- üì• T√©l√©chargement automatique et mise en cache
- üßπ Parsing intelligent des formats fran√ßais (CSV avec `;`, dates DD/MM/YYYY, d√©cimales `,`)
- üìä Chargement direct dans pandas DataFrames
- üìö Documentation compl√®te des datasets fr√©quemment utilis√©s
- üêç Librairie Python r√©utilisable et professionnelle

## Nouvelles fonctionnalit√©s v2.0.0

Cette version 2.0.0 ajoute le support du **MCP (Model Context Protocol) officiel de data.gouv.fr** en compl√©ment de notre librairie Python.

### Deux approches compl√©mentaires

**1. Notre librairie Python** (recommand√©e pour 80% des cas)
- ‚úÖ Simple : `pip install` et c'est tout
- ‚úÖ Offline : Cache local
- ‚úÖ Portable : Fonctionne partout
- ‚úÖ L√©ger : Pas de Docker ni serveur

**2. MCP officiel data.gouv.fr** (pour 20% des cas avanc√©s)
- ‚úÖ Requ√™tes SQL complexes via Hydra
- ‚úÖ Recherche dans toute la base
- ‚úÖ Cr√©ation de datasets
- ‚ö†Ô∏è N√©cessite Docker + configuration

### Comment choisir ?

**Utilisez notre librairie Python si :**
- Vous voulez t√©l√©charger et analyser des datasets
- Vous travaillez offline ou avec cache
- Vous faites des scripts automatis√©s
- Vous pr√©f√©rez la simplicit√©

**Utilisez le MCP officiel si :**
- Vous avez besoin de requ√™tes SQL complexes
- Vous voulez cr√©er/modifier des datasets
- Vous posez des questions en langage naturel sur les donn√©es

### Documentation

- **Guide de choix d√©taill√©** : [GUIDE_CHOIX.md](GUIDE_CHOIX.md)
- **Documentation MCP officiel** : [mcp/MCP_OFFICIEL.md](mcp/MCP_OFFICIEL.md)
- **Repository MCP officiel** : https://github.com/datagouv/datagouv-mcp

## Installation

### Via le marketplace Claude Code (recommand√©)

```bash
/plugin marketplace add benoitvx/data-gouv-skill
/plugin install data-gouv@data-gouv-skill
```

### Installation manuelle

```bash
# Installation globale (disponible dans tous les projets)
cd ~/.claude/skills
git clone https://github.com/benoitvx/data-gouv-skill.git

# OU installation par projet
cd /chemin/vers/votre/projet
mkdir -p .claude/skills
cd .claude/skills
git clone https://github.com/benoitvx/data-gouv-skill.git
```

### D√©pendances Python

```bash
pip install pandas requests openpyxl
```

## Utilisation rapide

Une fois install√©, vous pouvez directement utiliser la librairie dans Claude Code :

```python
# Importer la librairie
from data-gouv.lib.datagouv import DataGouvAPI, quick_search

# Recherche rapide
datasets = quick_search("vaccination")
for ds in datasets:
    print(f"{ds['title']} - {ds['organization']['name']}")

# Utilisation compl√®te de l'API
api = DataGouvAPI()

# Rechercher des datasets
results = api.search_datasets("qualit√© eau", page_size=10)

# Charger directement un CSV
df = api.load_csv("https://www.data.gouv.fr/fr/datasets/r/resource-id")

# Obtenir la derni√®re ressource d'un dataset
resource = api.get_latest_resource("dataset-id", format="csv")
```

## Structure du skill

```
data-gouv-skill/
‚îú‚îÄ‚îÄ .claude-plugin/
‚îÇ   ‚îú‚îÄ‚îÄ plugin.json          # M√©tadonn√©es du plugin
‚îÇ   ‚îî‚îÄ‚îÄ marketplace.json     # Configuration marketplace
‚îÇ
‚îú‚îÄ‚îÄ skills/data-gouv/
‚îÇ   ‚îú‚îÄ‚îÄ SKILL.md            # Ce fichier (point d'entr√©e)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ datagouv.py     # Librairie Python principale
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ datasets/           # Documentation des datasets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ iqvia-vaccination.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ eau-potable.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calendrier-scolaire.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ examples/           # Exemples de code
‚îÇ       ‚îú‚îÄ‚îÄ basic_search.py
‚îÇ       ‚îú‚îÄ‚îÄ vaccination_analysis.py
‚îÇ       ‚îú‚îÄ‚îÄ water_quality.py
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ sync-datasets.sh    # Synchroniser les m√©tadonn√©es
‚îÇ   ‚îî‚îÄ‚îÄ update-metadata.py  # Mettre √† jour la documentation
‚îÇ
‚îî‚îÄ‚îÄ README.md               # Documentation GitHub
```

## Datasets document√©s

Le skill inclut une documentation d√©taill√©e pour les datasets les plus utilis√©s :

### 1. IQVIA France - Vaccinations anti-grippales

**Organisation** : IQVIA France  
**Mise √† jour** : Hebdomadaire (campagne de vaccination)  
**Format** : CSV, XLSX

Donn√©es de suivi des campagnes de vaccination contre la grippe saisonni√®re, avec d√©tail par r√©gion, d√©partement, tranche d'√¢ge et type de site de vaccination.

**Documentation** : [datasets/iqvia-vaccination.md](datasets/iqvia-vaccination.md)

**Exemple d'utilisation** :
```python
# Rechercher le dataset de la campagne actuelle
results = api.search_datasets("vaccination grippe 2025-2026", organization="iqvia-france")
dataset_id = results['data'][0]['id']

# Charger les donn√©es
resource = api.get_latest_resource(dataset_id, format='csv')
df = api.load_csv(resource['url'])

# Filtrer par r√©gion
df_na = df[df['code_region'] == '75']  # Nouvelle-Aquitaine
print(f"Total vaccinations: {df_na['nb_doses'].sum():,}")
```

### 2. Contr√¥le sanitaire de l'eau potable

**Organisation** : Minist√®re de la Sant√©  
**Mise √† jour** : Mensuelle  
**Format** : CSV (fichiers volumineux)

R√©sultats complets des analyses de qualit√© de l'eau du robinet, commune par commune, avec tous les param√®tres test√©s (microbiologie, chimie, physico-chimie).

**Documentation** : [datasets/eau-potable.md](datasets/eau-potable.md)

**Exemple d'utilisation** :
```python
# Charger le fichier de correspondance communes/UDI
dataset_id = "resultats-du-controle-sanitaire-de-leau-distribuee-commune-par-commune"
dataset = api.get_dataset(dataset_id)

# Obtenir les donn√©es pour une commune
udi_com = api.load_csv(udi_com_resource_url)
udi_larochelle = udi_com[udi_com['codecommune'] == '17300']

# Analyser la conformit√©
results = api.load_csv(results_resource_url)
conformite = results['conforme'].value_counts()
taux = (conformite.get('O', 0) / len(results)) * 100
print(f"Taux de conformit√©: {taux:.1f}%")
```

### 3. Calendrier scolaire

**Organisation** : Minist√®re de l'√âducation Nationale  
**Mise √† jour** : Annuelle  
**Format** : CSV, JSON

Calendrier officiel des vacances scolaires par zone acad√©mique (A, B, C) et pour l'ensemble du territoire.

**Zones acad√©miques** :
- **Zone A** : Besan√ßon, Bordeaux, Clermont-Ferrand, Dijon, Grenoble, Limoges, Lyon, Poitiers
- **Zone B** : Aix-Marseille, Amiens, Caen, Lille, Nancy-Metz, Nantes, Nice, Orl√©ans-Tours, Reims, Rennes, Rouen, Strasbourg
- **Zone C** : Cr√©teil, Montpellier, Paris, Toulouse, Versailles

### Autres datasets disponibles

- Population l√©gale (INSEE)
- Code Officiel G√©ographique (COG)
- Qualit√© de l'air
- Production d'√©nergie renouvelable
- Transports publics (GTFS)
- Pharmacies et services de sant√©

## Librairie Python

### Classe principale : DataGouvAPI

```python
from data-gouv.lib.datagouv import DataGouvAPI

api = DataGouvAPI(cache_dir="/custom/cache/dir")  # optionnel
```

#### M√©thodes disponibles

**search_datasets(query, organization=None, tag=None, page_size=20, page=1)**
- Rechercher des datasets dans le catalogue
- Retourne : `Dict[str, Any]` avec r√©sultats et m√©tadonn√©es

**get_dataset(dataset_id)**
- Obtenir les d√©tails complets d'un dataset
- Retourne : `Dict[str, Any]` ou `None`

**get_latest_resource(dataset_id, format='csv', title_contains=None)**
- Obtenir la ressource la plus r√©cente d'un format donn√©
- Retourne : `Dict[str, Any]` ou `None`

**download_resource(resource_url, cache=True)**
- T√©l√©charger une ressource (avec cache automatique)
- Retourne : `bytes` ou `None`

**load_csv(resource_url, sep=None, encoding=None, decimal=',', cache=True)**
- Charger un CSV avec d√©tection automatique des formats fran√ßais
- Retourne : `pd.DataFrame` ou `None`

### Fonctions utilitaires

```python
from data-gouv.lib.datagouv import quick_search, load_dataset_csv

# Recherche rapide
datasets = quick_search("vaccination", limit=5)

# Chargement rapide d'un CSV
df = load_dataset_csv("dataset-id", resource_index=0)
```

## Exemples complets

### Analyse de vaccination par d√©partement

```python
from data-gouv.lib.datagouv import DataGouvAPI
import pandas as pd
import matplotlib.pyplot as plt

api = DataGouvAPI()

# Charger les donn√©es
results = api.search_datasets("vaccination grippe 2025-2026", organization="iqvia-france")
dataset_id = results['data'][0]['id']
resource = api.get_latest_resource(dataset_id, format='csv')
df = api.load_csv(resource['url'])

# Analyser par d√©partement en Nouvelle-Aquitaine
df_na = df[df['code_region'] == '75']
par_dept = df_na.groupby('libelle_departement')['nb_doses'].sum().sort_values()

# Visualiser
plt.figure(figsize=(12, 6))
par_dept.plot(kind='barh')
plt.title('Vaccinations anti-grippales par d√©partement (Nouvelle-Aquitaine)')
plt.xlabel('Nombre de doses')
plt.tight_layout()
plt.savefig('vaccinations_departement.png', dpi=150)
```

### Comparaison qualit√© de l'eau entre communes

```python
from data-gouv.lib.datagouv import DataGouvAPI

api = DataGouvAPI()

communes = {
    'La Rochelle': '17300',
    'Royan': '17306',
    'Saintes': '17415'
}

# Charger les donn√©es
dataset_id = "resultats-du-controle-sanitaire-de-leau-distribuee-commune-par-commune"
dataset = api.get_dataset(dataset_id)

# Analyser chaque commune
for nom, code in communes.items():
    # ... (voir datasets/eau-potable.md pour le code complet)
    print(f"{nom}: {taux_conformite:.1f}% de conformit√©")
```

## Bonnes pratiques

### 1. Utiliser le cache

Le cache est activ√© par d√©faut et √©conomise de la bande passante :

```python
api = DataGouvAPI(cache_dir="~/.cache/datagouv")
df = api.load_csv(url, cache=True)  # cache=True par d√©faut
```

### 2. G√©rer les fichiers volumineux

Pour les gros fichiers (>100 MB), charger par chunks :

```python
chunks = []
for chunk in pd.read_csv(url, chunksize=10000, sep=';', encoding='utf-8'):
    # Filtrer imm√©diatement
    chunk_filtered = chunk[chunk['region'] == 'Nouvelle-Aquitaine']
    chunks.append(chunk_filtered)

df = pd.concat(chunks, ignore_index=True)
```

### 3. Valider les donn√©es

Toujours v√©rifier la qualit√© des donn√©es charg√©es :

```python
df = api.load_csv(url)

if df is not None:
    print(f"‚úì Charg√©: {len(df)} lignes, {len(df.columns)} colonnes")
    print(f"‚úì Colonnes: {df.columns.tolist()}")
    print(f"‚úì P√©riode: {df['date'].min()} √† {df['date'].max()}")
else:
    print("‚úó Erreur de chargement")
```

### 4. Gestion des erreurs

```python
try:
    df = api.load_csv(url)
    if df is None:
        raise ValueError("Failed to load CSV")

    # Traiter les donn√©es
    result = df.groupby('region')['value'].sum()

except Exception as e:
    print(f"Erreur: {e}")
    # Fallback ou alternative
```

## Formats de donn√©es fran√ßais

### CSV
- **S√©parateur** : `;` (d√©tect√© automatiquement)
- **Encodage** : `utf-8`, `latin-1`, ou `cp1252` (d√©tect√© automatiquement)
- **D√©cimales** : `,` au lieu de `.` (g√©r√© automatiquement)

### Dates
- **Format courant** : `DD/MM/YYYY`
- **Format ISO** : `YYYY-MM-DD`
- **Semaines ISO** : `YYYY-Www` (ex: 2025-W42)

### Codes g√©ographiques
- **Commune** : Code INSEE 5 chiffres (ex: `17300`)
- **D√©partement** : 2 ou 3 chiffres (ex: `17`, `2A`, `2B`)
- **R√©gion** : 2 chiffres (ex: `75` pour Nouvelle-Aquitaine)

## Ressources et support

### Documentation officielle
- [data.gouv.fr](https://www.data.gouv.fr/)
- [API documentation](https://www.data.gouv.fr/fr/apidoc/)
- [Guide des producteurs](https://guides.data.gouv.fr/)

### Organisations principales
- **INSEE** : Statistiques, population, √©conomie
- **Minist√®re de la Sant√©** : Sant√© publique, qualit√© de l'eau
- **IQVIA France** : Campagnes de vaccination
- **Sant√© Publique France** : Surveillance sanitaire
- **Minist√®re de l'√âducation** : Donn√©es scolaires
- **Minist√®re de la Transition √âcologique** : Environnement, √©nergie

### Support du skill
- **Issues** : [GitHub Issues](https://github.com/benoitvx/data-gouv-skill/issues)
- **Contributions** : Pull requests bienvenues !
- **Licence** : Licence Ouverte 2.0 (compatible CC-BY)

## Contribution

Les contributions sont les bienvenues ! Pour ajouter un nouveau dataset document√© :

1. Cr√©er un fichier `datasets/nom-dataset.md`
2. Suivre le mod√®le des datasets existants
3. Ajouter des exemples de code concrets
4. Soumettre une pull request

## Changelog

### v2.0.0 (2025-12-02)
- üöÄ Ajout support MCP officiel data.gouv.fr
- üìù Guide de choix entre librairie Python et MCP
- üìö Documentation compl√®te du MCP officiel
- üîó Liens vers repository officiel
- ‚ú® Deux approches compl√©mentaires pour tous les cas d'usage

### v1.0.0 (2025-12-02)
- üéâ Version initiale
- ‚úÖ Librairie Python compl√®te
- ‚úÖ Documentation IQVIA Vaccination
- ‚úÖ Documentation Qualit√© de l'eau
- ‚úÖ Exemples de code
- ‚úÖ Cache automatique
- ‚úÖ Support formats fran√ßais

---

**Auteur** : Benoit Vinceneux
**Licence** : Licence Ouverte 2.0
**Version** : 2.0.0
**Derni√®re mise √† jour** : 2025-12-02
